{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f959816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 1. generate synthetic dataset\n",
    "\n",
    "np.random.seed(0)\n",
    "n_train, n_calib = 100, 100\n",
    "X = np.random.uniform(-5, 5, size=(n_train + n_calib, 1))\n",
    "y = 2 * X.squeeze() + np.random.normal(0, 1, size=(n_train + n_calib))\n",
    "\n",
    "X_train, y_train = X[:n_train], y[:n_train]\n",
    "X_calib, y_calib = X[n_train:], y[n_train:]\n",
    "\n",
    "# 2. fit base regression model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 3. define coverage policy\n",
    "\n",
    "class AlphaNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.initialize_to_one()\n",
    "    \n",
    "    def initialize_to_one(self):\n",
    "        with torch.no_grad():\n",
    "            self.fc2.weight.data.normal_(0, 0.01)\n",
    "            self.fc2.bias.data.fill_(5.0)  # sigmoid(5) â‰ˆ 0.993\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        return self.sigmoid(self.fc2(x)).squeeze(-1)\n",
    "\n",
    "def interval_size(scores, alpha):\n",
    "    \"\"\"\n",
    "    scores: tensor of shape (n,) -> S(X_j, Y_j)\n",
    "    alpha: scalar\n",
    "    returns: 2*r, the size of the conformal interval\n",
    "    \"\"\"\n",
    "    n = len(scores)\n",
    "    r = scores.sum() / (alpha * (n + 1) - 1)\n",
    "    return 2 * r\n",
    "\n",
    "# 4. build leave-one-out dataset features\n",
    "\n",
    "train_inputs = []\n",
    "n_calib = len(X_calib)\n",
    "\n",
    "for i in range(n_calib):\n",
    "    loo_X = np.delete(X_calib, i, axis=0)\n",
    "    loo_y = np.delete(y_calib, i, axis=0)\n",
    "    scores = np.abs(model.predict(loo_X) - loo_y)\n",
    "\n",
    "    # feature vector: [sum of LOO scores] only\n",
    "    input_feat = torch.tensor([scores.sum()], dtype=torch.float32)\n",
    "    train_inputs.append(input_feat)\n",
    "\n",
    "X_train_alpha = torch.stack(train_inputs)  # shape (n_calib, 1)\n",
    "\n",
    "# 5. training function\n",
    "\n",
    "def train_alpha_net(lambda_reg, run_id=0, num_epochs=50, batch_size=32):\n",
    "    train_dataset = TensorDataset(X_train_alpha, torch.arange(len(X_train_alpha)))  # dummy y\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    alpha_net = AlphaNet(input_dim=1).to(device)\n",
    "    optimizer = optim.Adam(alpha_net.parameters(), lr=1e-3)\n",
    "    \n",
    "    all_losses, all_sizes, all_alphas = [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        total_size = 0\n",
    "        total_alpha = 0\n",
    "        \n",
    "        for x_batch, idx_batch in train_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            alpha_pred = alpha_net(x_batch)\n",
    "            \n",
    "            batch_sizes = []\n",
    "            for j, idx in enumerate(idx_batch):\n",
    "                loo_X = np.delete(X_calib, idx.item(), axis=0)\n",
    "                loo_y = np.delete(y_calib, idx.item(), axis=0)\n",
    "                scores = torch.tensor(np.abs(model.predict(loo_X) - loo_y), dtype=torch.float32).to(device)\n",
    "                size_j = interval_size(scores, alpha_pred[j])\n",
    "                batch_sizes.append(size_j)\n",
    "            \n",
    "            batch_sizes = torch.stack(batch_sizes)\n",
    "            loss = (batch_sizes + lambda_reg * alpha_pred).mean()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_size += batch_sizes.mean().item()\n",
    "            total_alpha += alpha_pred.mean().item()\n",
    "        \n",
    "        all_losses.append(total_loss / len(train_loader))\n",
    "        all_sizes.append(total_size / len(train_loader))\n",
    "        all_alphas.append(total_alpha / len(train_loader))\n",
    "        \n",
    "        if epoch % 5 == 0 or epoch == num_epochs-1:\n",
    "            print(f\"Lambda {lambda_reg} | Run {run_id+1} | Epoch {epoch}/{num_epochs} | \"\n",
    "                  f\"Loss: {all_losses[-1]:.4f} | Mean Size: {all_sizes[-1]:.4f} | Mean Alpha: {all_alphas[-1]:.4f}\")\n",
    "    \n",
    "    return np.array(all_losses), np.array(all_sizes), np.array(all_alphas), alpha_net  \n",
    "\n",
    "# 6. run multiple lambdas and runs\n",
    "\n",
    "lambdas = [10, 20, 50]\n",
    "num_runs = 4\n",
    "all_results = {}\n",
    "\n",
    "for lam in lambdas:\n",
    "    losses_runs = []\n",
    "    sizes_runs = []\n",
    "    alphas_runs = []\n",
    "    for run in range(num_runs):\n",
    "        np.random.seed(run)\n",
    "        torch.manual_seed(run)\n",
    "        print(f\"\\nStarting Lambda {lam} | Run {run+1}/{num_runs}\")\n",
    "        losses, sizes, alphas, alpha_net = train_alpha_net(lambda_reg=lam, run_id=run)\n",
    "        losses_runs.append(losses)\n",
    "        sizes_runs.append(sizes)\n",
    "        alphas_runs.append(alphas)\n",
    "    all_results[lam] = {\n",
    "        'losses': np.array(losses_runs),\n",
    "        'sizes': np.array(sizes_runs),\n",
    "        'alphas': np.array(alphas_runs)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9fa6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from tueplots import bundles\n",
    "\n",
    "# extract arrays from all_results\n",
    "all_losses_10 = all_results[10]['losses']\n",
    "all_sizes_10 = all_results[10]['sizes']\n",
    "all_alphas_10 = all_results[10]['alphas']\n",
    "\n",
    "all_losses_20 = all_results[20]['losses']\n",
    "all_sizes_20 = all_results[20]['sizes']\n",
    "all_alphas_20 = all_results[20]['alphas']\n",
    "\n",
    "all_losses_50 = all_results[50]['losses']\n",
    "all_sizes_50 = all_results[50]['sizes']\n",
    "all_alphas_50 = all_results[50]['alphas']\n",
    "\n",
    "# define moving average smoothing function\n",
    "def moving_average(arr, window_size):\n",
    "    return np.convolve(arr, np.ones(window_size)/window_size, mode='valid')\n",
    "\n",
    "# smooth each run first, then average and std across runs\n",
    "def smooth_all(arr_2d, window):\n",
    "    smoothed_runs = []\n",
    "    for run in arr_2d:\n",
    "        smoothed = moving_average(run, window)\n",
    "        smoothed_runs.append(smoothed)\n",
    "    smoothed_runs = np.array(smoothed_runs)\n",
    "    mean = np.nanmean(smoothed_runs, axis=0)\n",
    "    std = np.nanstd(smoothed_runs, axis=0)\n",
    "    return mean, std\n",
    "\n",
    "window_size = 10\n",
    "\n",
    "# compute smoothed means and stds\n",
    "mean_loss_10, std_loss_10 = smooth_all(all_losses_10, window_size)\n",
    "mean_loss_20, std_loss_20 = smooth_all(all_losses_20, window_size)\n",
    "mean_loss_50, std_loss_50 = smooth_all(all_losses_50, window_size)\n",
    "\n",
    "mean_size_10, std_size_10 = smooth_all(all_sizes_10, window_size)\n",
    "mean_size_20, std_size_20 = smooth_all(all_sizes_20, window_size)\n",
    "mean_size_50, std_size_50 = smooth_all(all_sizes_50, window_size)\n",
    "\n",
    "mean_alpha_10, std_alpha_10 = smooth_all(all_alphas_10, window_size)\n",
    "mean_alpha_20, std_alpha_20 = smooth_all(all_alphas_20, window_size)\n",
    "mean_alpha_50, std_alpha_50 = smooth_all(all_alphas_50, window_size)\n",
    "\n",
    "# adjust epochs due to smoothing window\n",
    "epochs = np.arange(1, all_losses_10.shape[1] + 1)\n",
    "epochs_smoothed = epochs[:len(mean_loss_10)]\n",
    "\n",
    "# style setup\n",
    "plt.rcParams.update(bundles.icml2024())\n",
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": 18,\n",
    "    \"axes.titlesize\": 18,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    \"legend.fontsize\": 16,\n",
    "    \"lines.linewidth\": 2,\n",
    "    \"axes.linewidth\": 2,\n",
    "})\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "# colors for lambda = 10, 20, 50\n",
    "color_10 = \"#0077bb\"\n",
    "color_20 = \"#cc3311\"\n",
    "color_50 = \"#44aa99\"\n",
    "\n",
    "# plot 1: loss\n",
    "axs[0].plot(epochs_smoothed, mean_loss_10, label=r'$\\lambda=10$', color=color_10)\n",
    "axs[0].fill_between(epochs_smoothed, mean_loss_10-std_loss_10, mean_loss_10+std_loss_10, color=color_10, alpha=0.3)\n",
    "\n",
    "axs[0].plot(epochs_smoothed, mean_loss_20, label=r'$\\lambda=20$', color=color_20)\n",
    "axs[0].fill_between(epochs_smoothed, mean_loss_20-std_loss_20, mean_loss_20+std_loss_20, color=color_20, alpha=0.3)\n",
    "\n",
    "axs[0].plot(epochs_smoothed, mean_loss_50, label=r'$\\lambda=50$', color=color_50)\n",
    "axs[0].fill_between(epochs_smoothed, mean_loss_50-std_loss_50, mean_loss_50+std_loss_50, color=color_50, alpha=0.3)\n",
    "\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].set_title(\"Training Loss\")\n",
    "axs[0].grid(True)\n",
    "\n",
    "# plot 2: mean size \n",
    "axs[1].plot(epochs_smoothed, mean_size_10, label=r'$\\lambda=10$', color=color_10)\n",
    "axs[1].fill_between(epochs_smoothed, mean_size_10-std_size_10, mean_size_10+std_size_10, color=color_10, alpha=0.3)\n",
    "\n",
    "axs[1].plot(epochs_smoothed, mean_size_20, label=r'$\\lambda=20$', color=color_20)\n",
    "axs[1].fill_between(epochs_smoothed, mean_size_20-std_size_20, mean_size_20+std_size_20, color=color_20, alpha=0.3)\n",
    "\n",
    "axs[1].plot(epochs_smoothed, mean_size_50, label=r'$\\lambda=50$', color=color_50)\n",
    "axs[1].fill_between(epochs_smoothed, mean_size_50-std_size_50, mean_size_50+std_size_50, color=color_50, alpha=0.3)\n",
    "\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Mean Size\")\n",
    "axs[1].set_title(\"Mean Size per Epoch\")\n",
    "axs[1].grid(True)\n",
    "\n",
    "# plot 3: mean miscoverage\n",
    "axs[2].plot(epochs_smoothed, mean_alpha_10, label=r'$\\lambda=10$', color=color_10)\n",
    "axs[2].fill_between(epochs_smoothed, mean_alpha_10-std_alpha_10, mean_alpha_10+std_alpha_10, color=color_10, alpha=0.3)\n",
    "\n",
    "axs[2].plot(epochs_smoothed, mean_alpha_20, label=r'$\\lambda=20$', color=color_20)\n",
    "axs[2].fill_between(epochs_smoothed, mean_alpha_20-std_alpha_20, mean_alpha_20+std_alpha_20, color=color_20, alpha=0.3)\n",
    "\n",
    "axs[2].plot(epochs_smoothed, mean_alpha_50, label=r'$\\lambda=50$', color=color_50)\n",
    "axs[2].fill_between(epochs_smoothed, mean_alpha_50-std_alpha_50, mean_alpha_50+std_alpha_50, color=color_50, alpha=0.3)\n",
    "\n",
    "axs[2].set_xlabel(\"Epoch\")\n",
    "axs[2].set_ylabel(r\"Mean $\\tilde\\alpha$\")\n",
    "axs[2].set_title(r\"Mean $\\tilde\\alpha$ per Epoch\")\n",
    "axs[2].grid(True)\n",
    "axs[2].legend(frameon=True)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "    ax.yaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "    ax.tick_params(which='both', length=4)\n",
    "    ax.tick_params(which='minor', length=2, width=1.5)\n",
    "    ax.tick_params(which='major', width=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/reg_training.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc5f3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tueplots import bundles\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "\n",
    "# style setup\n",
    "plt.rcParams.update(bundles.icml2024())\n",
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": 18,\n",
    "    \"axes.titlesize\": 18,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    \"legend.fontsize\": 16,\n",
    "    \"lines.linewidth\": 2,\n",
    "    \"axes.linewidth\": 2,\n",
    "})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "\n",
    "# plot training data\n",
    "ax.scatter(X_train, y_train, color=\"#0077bb\", alpha=0.7, label=\"Training Data\")\n",
    "\n",
    "# plot fitted regression line\n",
    "x_line = np.linspace(-5, 5, 200).reshape(-1, 1)\n",
    "y_pred_line = model.predict(x_line)\n",
    "ax.plot(x_line, y_pred_line, color=\"black\", linewidth=2, label=r\"$f$\")\n",
    "\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.legend(frameon=True)\n",
    "ax.grid(True)\n",
    "\n",
    "ax.xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax.tick_params(which='both', length=4)\n",
    "ax.tick_params(which='minor', length=2, width=1.5)\n",
    "ax.tick_params(which='major', width=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/reg_data.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f75924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. evaluate conformal sets on test points using interval_size\n",
    "\n",
    "alpha_net.eval()\n",
    "\n",
    "# calibration scores\n",
    "scores_calib = np.abs(model.predict(X_calib) - y_calib)\n",
    "sum_scores = scores_calib.sum()\n",
    "\n",
    "# generate test features and labels\n",
    "X_test = np.random.uniform(-5, 5, size=(100, 1))\n",
    "y_test = 2 * X_test.squeeze() + np.random.normal(0, 1, size=100)\n",
    "\n",
    "feat = torch.tensor([sum_scores], dtype=torch.float32).to(device)\n",
    "alpha_val = alpha_net(feat).item()\n",
    "\n",
    "# compute conformal interval size\n",
    "size = interval_size(torch.tensor(scores_calib, dtype=torch.float32), alpha_val)\n",
    "\n",
    "# 8. plot size\n",
    "\n",
    "print(\"Mean conformal set size:\", size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d48e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. evaluate conformal sets on calibration points (LOO)\n",
    "\n",
    "sizes_calib = []\n",
    "n_calib = len(X_calib)\n",
    "\n",
    "for i in range(n_calib):\n",
    "    # leave-one-out scores\n",
    "    loo_X = np.delete(X_calib, i, axis=0)\n",
    "    loo_y = np.delete(y_calib, i, axis=0)\n",
    "    scores_loo = np.abs(model.predict(loo_X) - loo_y)\n",
    "\n",
    "    # feature vector for AlphaNet: only sum of LOO scores\n",
    "    feat_i = torch.tensor([scores_loo.sum()], dtype=torch.float32).to(device)\n",
    "    alpha_val = alpha_net(feat_i).item()\n",
    "\n",
    "    # compute conformal set size\n",
    "    size_i = interval_size(torch.tensor(scores_loo, dtype=torch.float32), alpha_val)\n",
    "    sizes_calib.append(size_i)\n",
    "\n",
    "# 10. plot histogram and mean size \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(sizes_calib, bins=10, edgecolor='k')\n",
    "plt.xlabel(\"Conformal set size\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of conformal set sizes (Calibration points, LOO)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean conformal set size (calibration, LOO):\", np.mean(sizes_calib))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
